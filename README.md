<!-- Project title and badges -->
# ğŸš€ Pret-Ã -DÃ©penser

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-%3E%3D3.8.1-orange.svg)](https://mlflow.org/)
[![CatBoost](https://img.shields.io/badge/CatBoost-%3E%3D1.2.8-blue.svg)](https://catboost.ai/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace--hub-%3E%3D1.2.3-purple.svg)](https://huggingface.co/)

**Packaging et dÃ©ploiement d'un modÃ¨le CatBoost avec MLflow et Hugging Face Hub.**

---

## ğŸ¯ Objectif

Automatiser une chaÃ®ne reproductible pour dÃ©ployer un modÃ¨le CatBoost :
- Enregistrement/versioning via MLflow
- Export des artifacts essentiels (`model.cb`, `MLmodel`, `input_example.json`)
- Publication et tÃ©lÃ©chargement depuis Hugging Face Hub
- Fournir une API HTTP via FastAPI pour la prÃ©diction et la gestion du modÃ¨le

---

## âœ¨ FonctionnalitÃ©s

- âœ… API FastAPI minimale pour health, inspection et scoring
- âœ… Chargement automatique du modÃ¨le au dÃ©marrage (injection dans `app.state`)
- âœ… Endpoints pour signature, info, statut et reload depuis HF
- âœ… PrÃ©diction individuelle et batch avec validation Pydantic
- âœ… Scripts d'upload/download vers/depuis Hugging Face Hub

---

## ğŸ“¡ Endpoints exposÃ©s

L'application FastAPI se trouve dans `src/app/main.py` et expose les routes suivantes (sans prÃ©fixe) :

- `GET /` â†’ redirection vers la documentation interactive `/docs`.
- `GET /api_health` â†’ Ã©tat de santÃ© global de l'API.

Routes du routeur (`src/app/routes.py`):
- `GET /router_health` â†’ health du router.
- `GET /model_status` â†’ Ã©tat du fichier modÃ¨le sur disque (`model.cb`).
- `GET /model_signature` â†’ colonnes attendues (signature MLflow) et nombre de features.
- `GET /model_info` â†’ mÃ©tadonnÃ©es (version, date, threshold recommandÃ©).
- `POST /individual_score` â†’ prÃ©diction pour un individu (Pydantic)
- `POST /multiple_score` â†’ prÃ©dictions en batch (liste d'objets Pydantic)
- `POST /reload_model` â†’ tÃ©lÃ©charge le fichier `HF_FILENAME` depuis `HF_REPO_ID` et recharge le modÃ¨le en mÃ©moire.

Exemple de payload (utilisez l'exemple depuis le schema `ScoringData` dans `src/app/schemas.py`):

```json
{
	"FE_EXT_SOURCE_MEAN": 0.5892,
	"BURO_MONTHS_BALANCE_SIZE_MEAN": 0.0,
	"CODE_GENDER": 0,
	"INSTAL_DPD_MEAN": 0.0,
	"BURO_MONTHS_BALANCE_MAX_MIN": 0.0,
	"FE_GOODS_CREDIT_RATE": 1.0,
	"APPROVED_CNT_PAYMENT_MEAN": 0.0,
	"YEARS_BIRTH": 59,
	"YEARS_EMPLOYED": 0,
	"AMT_ANNUITY": 20952.0,
	"NAME_FAMILY_STATUS_Married": true,
	"INSTAL_AMT_PAYMENT_SUM": 0.0,
	"FE_EXT_SOURCE_MIN": 0.2635,
	"PREV_CNT_PAYMENT_MEAN": 0.0,
	"FE_EXT_SOURCE_MAX": 0.7992
}
```

RÃ©ponse de prÃ©diction (exemple):

```json
{
	"score": 0.1234,
	"prediction": 0,
	"threshold": 0.5,
	"decision": "AccordÃ©"
}
```

---

## ğŸ“ Architecture & diagrammes

**Arborescence principale**

```
Pret-Ã -DÃ©penser/
â”‚
â”œâ”€â”€ âš™ï¸ config/                        # ParamÃ¨tres, chemins et logger
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ ğŸ“¦ exported_model/                # Artifacts exportÃ©s (Ã  ignorer)
â”‚   â”œâ”€â”€ MLmodel
â”‚   â”œâ”€â”€ model.cb
â”‚   â”œâ”€â”€ input_example.json
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ ğŸ§° scripts/                       # CLI helpers pour MLflow & HF
â”‚   â”œâ”€â”€ download_model_from_hf.py
â”‚   â”œâ”€â”€ upload_model_to_hf.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ’» src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ model.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ hf_interaction.py
â”‚   â”‚   â”œâ”€â”€ mlflow_interaction.py
â”‚   â”‚   â””â”€â”€ model_service.py
â”‚   â”œâ”€â”€ data_prep/
â”‚   â””â”€â”€ utils/
â”‚
â”œâ”€â”€ ğŸ§ª tests/
â”œâ”€â”€ ğŸ§¾ README.md
â”œâ”€â”€ ğŸ“œ pyproject.toml
â”œâ”€â”€ ğŸ“¦ requirements.txt
â”œâ”€â”€ ğŸ³ Dockerfile
â””â”€â”€ ğŸ³ docker-compose.yml
```

**Architecture (flow principal)**

```mermaid
graph TB
	A[Start API] --> B[Load model via `load_model_instance`]
	B --> C{Model in app.state}
	C -->|Yes| D[Ready for predictions]
	C -->|No| E[API runs but returns 503 on scoring]
	F[Reload request POST /reload_model] --> G[download_model_from_hf]
	G --> H[Store file in `MODEL_DIR`]
	H --> I[load_model_instance and update `app.state`]
```

```mermaid
sequenceDiagram
	participant Client
	participant API
	participant ModelService
	participant HF

	Client->>API: POST /individual_score â€” JSON
	API->>ModelService: validate & reorder inputs
	ModelService->>ModelService: model.predict_proba
	ModelService-->>API: score, decision
	API-->>Client: JSON response

	Client->>API: POST /reload_model
	API->>HF: hf_hub_download repo_id, filename
	HF-->>API: local file path
	API->>ModelService: load_model_instance
	API-->>Client: reload confirmation
```

---

## âš™ï¸ Variables d'environnement (importantes)

- `HF_REPO_ID` â€” identifiant du repo HF (ex: `username/model-repo`) requis pour `POST /reload_model`.
- `HUGGINGFACE_TOKEN` â€” token HF (ou `HF_TOKEN`) pour accÃ©der au repo privÃ©.
- `HF_FILENAME` â€” nom du fichier dans le repo HF (dÃ©faut `model.cb`).
- `MLFLOW_TRACKING_URI` â€” (optionnel) point vers le serveur MLflow.

Ces variables peuvent Ãªtre mises dans `.devenv` (utilisÃ© par le projet) ou exportÃ©es dans votre CI.

---

## ğŸ§° Installation rapide

Prerequis: Python 3.13+

```bash
python -m venv .venv
.venv\Scripts\activate   # Windows
pip install -e .
```

Le projet s'appuie sur les dÃ©pendances listÃ©es dans `pyproject.toml`.

### Lancer l'API localement (dev)

La workspace contient une task pour dÃ©marrer l'API :

```bash
uv run uvicorn src.app.main:app --host 0.0.0.0 --port 8000 --reload
```

L'UI interactive est disponible sur `http://localhost:8000/docs`.

### Lancer MLflow (optionnel)

```bash
mlflow server --host 0.0.0.0 --port 5000
```

---

## ğŸ³ Docker

Le `Dockerfile` du projet utilise le gestionnaire `uv` (voir Dockerfile). Le `docker-compose.yml` expose le port `8000`.

---

## ğŸ§ª Tests

Utilisez `pytest` pour lancer la suite de tests (si prÃ©sente) :

```bash
pytest -q
```

---

## ğŸ‘¤ Auteur & remerciements

**Fabien** - [RandomFab](https://github.com/RandomFab)

Merci aux bibliothÃ¨ques et projets open-source utilisÃ©s : FastAPI, MLflow, CatBoost, HuggingFace Hub.
