<!-- Project title and badges -->
# üöÄ Pret-√†-D√©penser

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-%3E%3D3.8.1-orange.svg)](https://mlflow.org/)
[![CatBoost](https://img.shields.io/badge/CatBoost-%3E%3D1.2.8-blue.svg)](https://catboost.ai/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace--hub-%3E%3D1.2.3-purple.svg)](https://huggingface.co/)

**Packaging et d√©ploiement d'un mod√®le CatBoost avec MLflow et Hugging Face Hub.**

---

## üéØ Objectif

Automatiser une cha√Æne reproductible pour d√©ployer un mod√®le CatBoost :
- Enregistrement/versioning via MLflow
- Export des artifacts essentiels (`model.cb`, `MLmodel`, `input_example.json`)
- Publication et t√©l√©chargement depuis Hugging Face Hub
- Fournir une API HTTP via FastAPI pour la pr√©diction et la gestion du mod√®le

---

## ‚ú® Fonctionnalit√©s

- ‚úÖ API FastAPI minimale pour health, inspection et scoring
- ‚úÖ Chargement automatique du mod√®le au d√©marrage (injection dans `app.state`)
- ‚úÖ Endpoints pour signature, info, statut et reload depuis HF
- ‚úÖ Pr√©diction individuelle et batch avec validation Pydantic
- ‚úÖ Scripts d'upload/download vers/depuis Hugging Face Hub

---

## üì° Endpoints expos√©s

L'application FastAPI se trouve dans `src/api/main.py` et expose les routes suivantes (sans pr√©fixe). Le frontend Streamlit se trouve dans `src/app/main.py` et communique avec l'API pour afficher l'interface utilisateur :

- `GET /` ‚Üí redirection vers la documentation interactive `/docs`.
- `GET /api_health` ‚Üí √©tat de sant√© global de l'API.

Routes du routeur (`src/api/routes.py`):
- `GET /router_health` ‚Üí health du router.
- `GET /model_status` ‚Üí √©tat du fichier mod√®le sur disque (`model.cb`).
- `GET /model_signature` ‚Üí colonnes attendues (signature MLflow) et nombre de features.
- `GET /model_info` ‚Üí m√©tadonn√©es (version, date, threshold recommand√©).
- `POST /individual_score` ‚Üí pr√©diction pour un individu (Pydantic)
- `POST /multiple_score` ‚Üí pr√©dictions en batch (liste d'objets Pydantic)
- `POST /reload_model` ‚Üí t√©l√©charge le fichier `HF_FILENAME` depuis `HF_REPO_ID` et recharge le mod√®le en m√©moire.

Exemple de payload (utilisez l'exemple depuis le schema `ScoringData` dans `src/app/schemas.py`):

```json
{
	"FE_EXT_SOURCE_MEAN": 0.5892,
	"BURO_MONTHS_BALANCE_SIZE_MEAN": 0.0,
	"CODE_GENDER": 0,
	"INSTAL_DPD_MEAN": 0.0,
	"BURO_MONTHS_BALANCE_MAX_MIN": 0.0,
	"FE_GOODS_CREDIT_RATE": 1.0,
	"APPROVED_CNT_PAYMENT_MEAN": 0.0,
	"YEARS_BIRTH": 59,
	"YEARS_EMPLOYED": 0,
	"AMT_ANNUITY": 20952.0,
	"NAME_FAMILY_STATUS_Married": true,
	"INSTAL_AMT_PAYMENT_SUM": 0.0,
	"FE_EXT_SOURCE_MIN": 0.2635,
	"PREV_CNT_PAYMENT_MEAN": 0.0,
	"FE_EXT_SOURCE_MAX": 0.7992
}
```

R√©ponse de pr√©diction (exemple):

```json
{
	"score": 0.1234,
	"prediction": 0,
	"threshold": 0.5,
	"decision": "Accord√©"
}
```

---

## üìÅ Architecture & diagrammes

**Arborescence principale**

```
Pret-√†-D√©penser/
‚îÇ
‚îú‚îÄ‚îÄ ‚öôÔ∏è config/                        # Param√®tres, chemins et logger
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îÇ
‚îú‚îÄ‚îÄ üì¶ exported_model/                # Artifacts export√©s (√† ignorer)
‚îÇ   ‚îú‚îÄ‚îÄ MLmodel
‚îÇ   ‚îú‚îÄ‚îÄ model.cb
‚îÇ   ‚îú‚îÄ‚îÄ input_example.json
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ external/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ
‚îú‚îÄ‚îÄ üß∞ scripts/                       # CLI helpers pour MLflow & HF
‚îÇ   ‚îú‚îÄ‚îÄ download_model_from_hf.py
‚îÇ   ‚îú‚îÄ‚îÄ upload_model_to_hf.py
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ üíª src/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hf_interaction.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlflow_interaction.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_service.py
‚îÇ   ‚îú‚îÄ‚îÄ data_prep/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/
‚îú‚îÄ‚îÄ üßæ README.md
‚îú‚îÄ‚îÄ üìú pyproject.toml
‚îú‚îÄ‚îÄ üì¶ requirements.txt
‚îú‚îÄ‚îÄ üê≥ Dockerfile
‚îî‚îÄ‚îÄ üê≥ docker-compose.yml
```

**Architecture (flow principal)**

```mermaid
graph TB
	A[Start API] --> B[Load model via `load_model_instance`]
	B --> C{Model in app.state}
	C -->|Yes| D[Ready for predictions]
	C -->|No| E[API runs but returns 503 on scoring]
	F[Reload request POST /reload_model] --> G[download_model_from_hf]
	G --> H[Store file in `MODEL_DIR`]
	H --> I[load_model_instance and update `app.state`]
```

```mermaid
sequenceDiagram
	participant Client
	participant API
	participant ModelService
	participant HF

	Client->>API: POST /individual_score ‚Äî JSON
	API->>ModelService: validate & reorder inputs
	ModelService->>ModelService: model.predict_proba
	ModelService-->>API: score, decision
	API-->>Client: JSON response

	Client->>API: POST /reload_model
	API->>HF: hf_hub_download repo_id, filename
	HF-->>API: local file path
	API->>ModelService: load_model_instance
	API-->>Client: reload confirmation
```

---

## ‚öôÔ∏è Variables d'environnement (importantes)

- `HF_REPO_ID` ‚Äî identifiant du repo HF (ex: `username/model-repo`) requis pour `POST /reload_model`.
- `HUGGINGFACE_TOKEN` ‚Äî token HF (ou `HF_TOKEN`) pour acc√©der au repo priv√©.
- `HF_FILENAME` ‚Äî nom du fichier dans le repo HF (d√©faut `model.cb`).
- `MLFLOW_TRACKING_URI` ‚Äî (optionnel) point vers le serveur MLflow.

Ces variables peuvent √™tre mises dans `.devenv` (utilis√© par le projet) ou export√©es dans votre CI.

---

## üß∞ Installation rapide

Prerequis: Python 3.13+

```bash
python -m venv .venv
.venv\Scripts\activate   # Windows
pip install -e .
```

Le projet s'appuie sur les d√©pendances list√©es dans `pyproject.toml`.

### Lancer l'API localement (dev)

La workspace contient une task pour d√©marrer l'API :

```bash
uv run uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

L'UI interactive est disponible sur `http://localhost:8000/docs`.

### Lancer le frontend Streamlit (dev)

Le projet contient aussi une application Streamlit pour une UI de scoring. Vous pouvez la lancer avec la task VS Code ou la commande suivante :

```bash
uv run streamlit run src/app/main.py
```

L'interface Streamlit est accessible par d√©faut sur `http://localhost:8501`.

### Lancer MLflow (optionnel)

```bash
mlflow server --host 0.0.0.0 --port 5000
```

---

## üê≥ Docker

Le `Dockerfile` du projet utilise le gestionnaire `uv` (voir Dockerfile). Le `docker-compose.yml` expose le port `8000`.

---

## üß™ Tests

Utilisez `pytest` pour lancer la suite de tests (si pr√©sente) :

```bash
pytest -q
```

---

## üë§ Auteur & remerciements

**Fabien** - [RandomFab](https://github.com/RandomFab)

Merci aux biblioth√®ques et projets open-source utilis√©s : FastAPI, MLflow, CatBoost, HuggingFace Hub.
