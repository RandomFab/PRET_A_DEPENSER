<!-- Project title and badges -->
# üöÄ Pret-√†-D√©penser

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.128+-green.svg)](https://fastapi.tiangolo.com/)
[![MLflow](https://img.shields.io/badge/MLflow-%3E%3D3.8.1-orange.svg)](https://mlflow.org/)
[![CatBoost](https://img.shields.io/badge/CatBoost-%3E%3D1.2.8-blue.svg)](https://catboost.ai/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace--hub-%3E%3D1.2.3-purple.svg)](https://huggingface.co/)

**Packaging et d√©ploiement d'un mod√®le CatBoost avec MLflow et Hugging Face Hub.**

---

## üéØ Objectif

Automatiser une cha√Æne reproductible pour d√©ployer un mod√®le CatBoost :
- Enregistrement/versioning via MLflow
- Export des artifacts essentiels (`model.cb`, `MLmodel`, `input_example.json`)
- Publication et t√©l√©chargement depuis Hugging Face Hub
- Fournir une API HTTP via FastAPI pour la pr√©diction et la gestion du mod√®le

---

## ‚ú® Fonctionnalit√©s

- ‚úÖ API FastAPI minimale pour health, inspection et scoring
- ‚úÖ Chargement automatique du mod√®le au d√©marrage (injection dans `app.state`)
- ‚úÖ Endpoints pour signature, info, statut et reload depuis HF
- ‚úÖ Pr√©diction individuelle et batch avec validation Pydantic
- ‚úÖ Scripts d'upload/download vers/depuis Hugging Face Hub

---

## üì° Endpoints expos√©s

L'application FastAPI se trouve dans `src/api/main.py` et expose les routes suivantes (sans pr√©fixe). Le frontend Streamlit se trouve dans `src/app/main.py` et communique avec l'API pour afficher l'interface utilisateur :

- `GET /` ‚Üí redirection vers la documentation interactive `/docs`.
- `GET /api_health` ‚Üí √©tat de sant√© global de l'API.

Routes du routeur (`src/api/routes.py`):
- `GET /router_health` ‚Üí health du router.
- `GET /model_status` ‚Üí √©tat du fichier mod√®le sur disque (`model.cb`).
- `GET /model_signature` ‚Üí colonnes attendues (signature MLflow) et nombre de features.
- `GET /model_info` ‚Üí m√©tadonn√©es (version, date, threshold recommand√©).
- `POST /individual_score` ‚Üí pr√©diction pour un individu (Pydantic)
- `POST /multiple_score` ‚Üí pr√©dictions en batch (liste d'objets Pydantic)
- `POST /reload_model` ‚Üí t√©l√©charge le fichier `HF_FILENAME` depuis `HF_REPO_ID` et recharge le mod√®le en m√©moire.

Exemple de payload (utilisez l'exemple depuis le schema `ScoringData` dans `src/app/schemas.py`):

```json
{
	"FE_EXT_SOURCE_MEAN": 0.5892,
	"BURO_MONTHS_BALANCE_SIZE_MEAN": 0.0,
	"CODE_GENDER": 0,
	"INSTAL_DPD_MEAN": 0.0,
	"BURO_MONTHS_BALANCE_MAX_MIN": 0.0,
	"FE_GOODS_CREDIT_RATE": 1.0,
	"APPROVED_CNT_PAYMENT_MEAN": 0.0,
	"YEARS_BIRTH": 59,
	"YEARS_EMPLOYED": 0,
	"AMT_ANNUITY": 20952.0,
	"NAME_FAMILY_STATUS_Married": true,
	"INSTAL_AMT_PAYMENT_SUM": 0.0,
	"FE_EXT_SOURCE_MIN": 0.2635,
	"PREV_CNT_PAYMENT_MEAN": 0.0,
	"FE_EXT_SOURCE_MAX": 0.7992
}
```

R√©ponse de pr√©diction (exemple):

```json
{
	"score": 0.1234,
	"prediction": 0,
	"threshold": 0.5,
	"decision": "Accord√©"
}
```

---

## üìÅ Architecture & diagrammes

**Arborescence principale**

```text
PRET_A_DEPENSER/
‚îú‚îÄ‚îÄ üìÇ config/               # Configuration (chemins, logger, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îî‚îÄ‚îÄ logger.py
‚îú‚îÄ‚îÄ üìÇ data/                 # Donn√©es (raw, processed)
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ scoring_template_app.csv
‚îú‚îÄ‚îÄ üìÇ scripts/              # Utilitaires HF (upload/download)
‚îÇ   ‚îú‚îÄ‚îÄ download_model_from_hf.py
‚îÇ   ‚îî‚îÄ‚îÄ upload_model_to_hf.py
‚îú‚îÄ‚îÄ üìÇ src/                  # Code source
‚îÇ   ‚îú‚îÄ‚îÄ üé® api/              # Backend FastAPI (Mod√®le, Routes, Schemas)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ üß† app/              # Frontend Streamlit
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îÇ   ‚îî‚îÄ‚îÄ ‚öôÔ∏è model/            # Logique m√©tier & Hubs (MLflow, HF)
‚îÇ       ‚îú‚îÄ‚îÄ hf_interaction.py
‚îÇ       ‚îú‚îÄ‚îÄ mlflow_interaction.py
‚îÇ       ‚îî‚îÄ‚îÄ model_service.py
‚îú‚îÄ‚îÄ üß™ tests/                # Tests unitaires et fonctionnels
‚îú‚îÄ‚îÄ üê≥ Dockerfile            # Packaging Docker
‚îú‚îÄ‚îÄ üêô docker-compose.yml    # Orchestration locale
‚îî‚îÄ‚îÄ üöÄ start.sh             # Script de d√©marrage dual (API + App)
```

**Architecture (flow principal)**

```mermaid
graph TB
	A[Start API] --> B[Load model via `load_model_instance`]
	B --> C{Model in app.state}
	C -->|Yes| D[Ready for predictions]
	C -->|No| E[API runs but returns 503 on scoring]
	F[Reload request POST /reload_model] --> G[download_model_from_hf]
	G --> H[Store file in `MODEL_DIR`]
	H --> I[load_model_instance and update `app.state`]
```
--- 

```mermaid
sequenceDiagram
	participant Client
	participant API
	participant ModelService
	participant HF

	Client->>API: POST /individual_score ‚Äî JSON
	API->>ModelService: validate & reorder inputs
	ModelService->>ModelService: model.predict_proba
	ModelService-->>API: score, decision
	API-->>Client: JSON response

	Client->>API: POST /reload_model
	API->>HF: hf_hub_download repo_id, filename
	HF-->>API: local file path
	API->>ModelService: load_model_instance
	API-->>Client: reload confirmation
```

---

## ‚öôÔ∏è Variables d'environnement (importantes)

- `HF_REPO_ID` ‚Äî identifiant du repo HF (ex: `username/model-repo`) requis pour `POST /reload_model`.
- `HUGGINGFACE_TOKEN` ‚Äî token HF (ou `HF_TOKEN`) pour acc√©der au repo priv√©.
- `HF_FILENAME` ‚Äî nom du fichier dans le repo HF (d√©faut `model.cb`).
- `MLFLOW_TRACKING_URI` ‚Äî (optionnel) point vers le serveur MLflow.

Ces variables peuvent √™tre mises dans `.devenv` (utilis√© par le projet) ou export√©es dans votre CI.

---

## üöÄ Installation & D√©ploiement Local

### üêç Installation D√©veloppement (venv)
Pr√©r√©quis : **Python 3.13+** et **uv** (recommand√©).

1.  **Cloner le d√©p√¥t** :
    ```bash
    git clone https://github.com/RandomFab/PRET_A_DEPENSER.git
    cd PRET_A_DEPENSER
    ```
2.  **Installer les d√©pendances** :
    ```bash
    uv sync --frozen
    ```
3.  **Lancer s√©par√©ment (Dev)** :
    - **API** : `uv run uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload`
    - **App** : `uv run streamlit run src/app/main.py --server.port 7860`

---

## üê≥ D√©ploiement Local (Docker)

La m√©thode la plus simple pour reproduire l'environnement de production.

1.  **Configuration** : Cr√©ez un fichier `.devenv` avec vos tokens si n√©cessaire.
2.  **Lancement** :
    ```bash
    docker compose up --build -d
    ```
3.  **Acc√®s** :
    - **Streamlit (UI)** : [http://localhost:7860](http://localhost:7860)
    - **FastAPI (Docs)** : [http://localhost:8000/docs](http://localhost:8000/docs)

Le conteneur utilise le script `start.sh` pour orchestrer le d√©marrage de l'API, attendre son initialisation, puis lancer l'interface Streamlit.  
HF ne proposant qu'un port (7870), c'est la m√©thode la plus simple pour d√©ployer le couple API + APP.  
Un multi-conteners serait plus appropri√© sur un VPS par exemple.

---

## üß™ Tests & Qualit√©

La suite de tests utilise `pytest` et g√©n√®re un rapport de couverture.

```bash
uv run pytest --cov=src --cov-report=html
```
Le rapport est g√©n√©r√© dans `htmlcov/index.html`.

---

## ü§ñ CI/CD (GitHub Actions)

Le projet int√®gre une pipeline automatis√©e (`.github/workflows/ci-cd.yml`) :
- **Test Job** : Ex√©cut√© sur `push/PR` (main & develop). Installe les d√©pendances, lance les tests et exporte le rapport de couverture.
- **Deploiement Job** : D√©clenche automatiquement le d√©ploiement vers **Hugging Face Spaces** lors d'un push sur `main`.

---

## üë§ Auteur & remerciements

**Fabien** - [RandomFab](https://github.com/RandomFab)

Merci aux biblioth√®ques et projets open-source utilis√©s : FastAPI, MLflow, CatBoost, HuggingFace Hub.
